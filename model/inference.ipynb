{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade onnxruntime"
      ],
      "metadata": {
        "id": "IIgfTwmZZjc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='skyblue' size='6em'>#1 LOAD ONNX and JSON FILES</font>"
      ],
      "metadata": {
        "id": "MnOlvfIB1jWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import onnxruntime\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load configuration files\n",
        "tokenizer_config = json.load(open('/content/pix2struct_onnx/tokenizer_config.json', 'r'))\n",
        "preprocessor_config = json.load(open('/content/pix2struct_onnx/preprocessor_config.json', 'r'))\n",
        "preprocessor_config[\"target_size\"] = (64, 64)\n",
        "\n",
        "# Load ONNX models\n",
        "encoder_model = onnxruntime.InferenceSession('/content/pix2struct_onnx/encoder_model.onnx')\n",
        "decoder_with_past_model = onnxruntime.InferenceSession('/content/pix2struct_onnx/decoder_with_past_model.onnx')\n",
        "decoder_model = onnxruntime.InferenceSession('/content/pix2struct_onnx/decoder_model.onnx')"
      ],
      "metadata": {
        "id": "rpYeUYsJ1SAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d2Xj_vH9110U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "<font color='skyblue' size='6em'>#2 PRE PROCESS THE IMAGE</font>"
      ],
      "metadata": {
        "id": "Dd5tdZkM15IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess the image\n",
        "def preprocess_image(image_path_or_url):\n",
        "    if image_path_or_url.startswith(\"http\"):\n",
        "        response = requests.get(image_path_or_url, stream=True)\n",
        "        response.raise_for_status()\n",
        "        image = Image.open(io.BytesIO(response.content))\n",
        "    else:\n",
        "        image = Image.open(image_path_or_url)\n",
        "\n",
        "    # Resize the image to the target size\n",
        "    width, height = preprocessor_config[\"target_size\"]\n",
        "    image = image.resize((width, height))\n",
        "\n",
        "    # Normalize the image\n",
        "    image = np.array(image) / 255.0\n",
        "    image = image.astype(np.float32)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "9qG4LbF71br5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='skyblue' size='6em'>#3 RUN INFERENCE ON THREE SUBMODELS</font>"
      ],
      "metadata": {
        "id": "BSegWBE_2AGU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QBRACx7YFjp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load and preprocess the image (provide either local path or image URL)\n",
        "image_path_or_url = \"https://cdn-clekk.nitrocdn.com/tkvYXMZryjYrSVhxKeFTeXElceKUYHeV/assets/images/optimized/rev-82dec77/wp-content/uploads/2021/05/machine-learning-types-infographics_1-1536x695.png\"  # or image URL\n",
        "preprocessed_image = preprocess_image(image_path_or_url)\n",
        "\n",
        "# Encode the image\n",
        "flattened_patches = np.expand_dims(preprocessed_image, axis=0)\n",
        "attention_mask = np.ones((1, preprocessed_image.shape[0], preprocessed_image.shape[1], 1))\n",
        "\n",
        "# Convert flattened_patches to int64 data type\n",
        "flattened_patches_int64 = flattened_patches.astype(np.int64)\n",
        "\n",
        "# Run inference on the encoder model\n",
        "encoder_input = {'flattened_patches': flattened_patches_int64, 'attention_mask': attention_mask}\n",
        "encoder_output = encoder_model.run(None, encoder_input)\n",
        "\n",
        "\n",
        "# Run inference on the decoder with past model\n",
        "decoder_with_past_input = {'encoder_output': encoder_output}\n",
        "decoder_with_past_output = decoder_with_past_model.run(None, decoder_with_past_input)\n",
        "\n",
        "# Run inference on the decoder model\n",
        "decoder_input = {'past_key_values': decoder_with_past_output}\n",
        "decoder_output = decoder_model.run(None, decoder_input)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='skyblue' size='6em'>#4 DISPLAY GENERATED TEXT</font>"
      ],
      "metadata": {
        "id": "ua-5_VqW2KCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Post-process the generated text\n",
        "generated_text = tokenizer_config[\"token_to_text\"][np.argmax(decoder_output[0])]\n",
        "\n",
        "# Display or save the generated text\n",
        "print(\"Generated Text:\", generated_text)"
      ],
      "metadata": {
        "id": "sVYiWT971iE8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}